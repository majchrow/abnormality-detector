{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext, Row\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import platform\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import pyspark.sql.functions as func\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--packages com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1 --conf spark.cassandra.connection.host=127.0.0.1 --conf spark.cassandra.connection.port=9042 --conf spark.cassandra.auth.username=cassandra --conf spark.cassandra.auth.password=cassandra pyspark-shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_BOOTSTRAP_SERVER = \"localhost:9092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"LogsAnalysisWithSpark\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = spark.read.json(\"logs/calls_data.json\")\n",
    "schema = sample.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream_for_topics(topics, spark, kafka_server):\n",
    "    return spark.readStream\\\n",
    "    .format(\"kafka\")\\\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_server)\\\n",
    "    .option(\"subscribe\", \",\".join(topics))\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "streamingInputDF = get_stream_for_topics([\"callListUpdate\", \"callInfoUpdate\"], spark, KAFKA_BOOTSTRAP_SERVER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesDF = streamingInputDF.selectExpr(\"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsDF = valuesDF.withColumn(\"event\", from_json(valuesDF.value, schema)).select(\"event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event: struct (nullable = true)\n",
      " |    |-- date: string (nullable = true)\n",
      " |    |-- message: struct (nullable = true)\n",
      " |    |    |-- messageId: long (nullable = true)\n",
      " |    |    |-- subscriptionIndex: long (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- updates: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- call: string (nullable = true)\n",
      " |    |    |    |    |-- callCorrelator: string (nullable = true)\n",
      " |    |    |    |    |-- callType: string (nullable = true)\n",
      " |    |    |    |    |-- distributedInstances: long (nullable = true)\n",
      " |    |    |    |    |-- endpointRecording: string (nullable = true)\n",
      " |    |    |    |    |-- lockState: string (nullable = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |-- participants: long (nullable = true)\n",
      " |    |    |    |    |-- reason: string (nullable = true)\n",
      " |    |    |    |    |-- recording: string (nullable = true)\n",
      " |    |    |    |    |-- streaming: string (nullable = true)\n",
      " |    |    |    |    |-- updateType: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eventsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "messagesDF = eventsDF.withColumn(\"date\", eventsDF.event.date)\\\n",
    "                     .withColumn(\"message\", eventsDF.event.message)\\\n",
    "                     .select(\"message\", \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedDF = messagesDF.select(\"date\", explode(messagesDF.message.updates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- col: struct (nullable = true)\n",
      " |    |-- call: string (nullable = true)\n",
      " |    |-- callCorrelator: string (nullable = true)\n",
      " |    |-- callType: string (nullable = true)\n",
      " |    |-- distributedInstances: long (nullable = true)\n",
      " |    |-- endpointRecording: string (nullable = true)\n",
      " |    |-- lockState: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- participants: long (nullable = true)\n",
      " |    |-- reason: string (nullable = true)\n",
      " |    |-- recording: string (nullable = true)\n",
      " |    |-- streaming: string (nullable = true)\n",
      " |    |-- updateType: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessedDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = preprocessedDF.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = preprocessedDF.select(col.call.alias(\"call\"),\n",
    "                      col.callCorrelator.alias(\"callCorrelator\"),\n",
    "                      col.callType.alias(\"callType\"),\n",
    "                      col.distributedInstances.alias(\"distributedInstances\"),\n",
    "                      col.endpointRecording.alias(\"endpointRecording\"),\n",
    "                      col.lockState.alias(\"lockState\"),\n",
    "                      col.participants.alias(\"participants\"),\n",
    "                      col.reason.alias(\"reason\"),\n",
    "                      col.recording.alias(\"recording\"),\n",
    "                      col.streaming.alias(\"streaming\"),\n",
    "                      col.updateType.alias(\"updateType\"),\n",
    "                      preprocessedDF.date\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Czas rzeczywisty -> current_time\n",
    "# Czas od rozpoczęcia spotkania -> time_diff\n",
    "# Spotkanie nagrywane -> recording\n",
    "# Spotkanie streamowane -> streaming\n",
    "# Spotkanie zablokowane -> locked\n",
    "# Spotkanie adHoc -> adhoc\n",
    "# Spotkanie\n",
    "# Aktualna liczba uczestników -> current_participants\n",
    "# Średnia liczba uczestników w danym spotkaniu -> mean_participants\n",
    "# Maxymalna liczba uczestników danego spotkania -> max_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedDF = finalDF.groupBy(\"call\")\\\n",
    "                       .agg(func.sort_array(func.collect_list(finalDF.date)).alias(\"dateArray\"), \n",
    "                        func.collect_list(finalDF.recording).alias(\"recordingArray\"),\n",
    "                        func.collect_list(finalDF.streaming).alias(\"streamingArray\"),\n",
    "                        func.collect_list(finalDF.lockState).alias(\"lockStateArray\"),\n",
    "                        reverse(func.collect_list(finalDF.callType)).getItem(0).alias(\"callType\"),\n",
    "                        reverse(func.collect_list(finalDF.participants)).getItem(0).alias(\"current_participants\"),\n",
    "                        func.max(finalDF.participants).alias(\"max_participants\"),\n",
    "                        func.mean(finalDF.participants).alias(\"mean_participants\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- call: string (nullable = true)\n",
      " |-- dateArray: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- recordingArray: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- streamingArray: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- lockStateArray: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- callType: string (nullable = true)\n",
      " |-- current_participants: long (nullable = true)\n",
      " |-- max_participants: long (nullable = true)\n",
      " |-- mean_participants: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groupedDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(dates):\n",
    "    pattern = '%Y-%m-%dT%H:%M:%S.%f'\n",
    "    start_date = datetime.strptime(dates[0], pattern)\n",
    "    end_date = datetime.strptime(dates[-1], pattern)\n",
    "    return int((end_date - start_date).total_seconds())\n",
    "\n",
    "find_diff_udf = udf(lambda x: find_diff(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_date(dates):\n",
    "    return dates[-1]\n",
    "\n",
    "get_last_date_udf = udf(lambda x: get_last_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_nonempty_value(values):\n",
    "    nonempty_values = [i for i in values if i]\n",
    "    return nonempty_values[-1] if nonempty_values else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_if_active(values):\n",
    "    state = get_last_nonempty_value(values)\n",
    "    return state == \"active\"    \n",
    "    \n",
    "get_if_active_udf = udf(lambda x: get_if_active(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_if_locked(values):\n",
    "    state = get_last_nonempty_value(values)\n",
    "    return state == \"locked\"\n",
    "\n",
    "get_if_locked_udf = udf(lambda x: get_if_locked(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_if_type(current_type, expected_type):\n",
    "    return current_type == expected_type\n",
    "\n",
    "get_if_adhoc_udf = udf(lambda x: get_if_type(x, \"adHoc\"))\n",
    "get_if_lync_udf = udf(lambda x: get_if_type(x, \"lyncConferencing\"))\n",
    "get_if_forwarding_udf = udf(lambda x: get_if_type(x, \"forwarding\"))\n",
    "get_if_cospace_udf = udf(lambda x: get_if_type(x, \"coSpace\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_udf = udf(lambda cols: \"\".join([x if x is not None else \"*\" for x in cols]), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = groupedDF\\\n",
    "                .withColumn(\"current_time\", get_last_date_udf(groupedDF.dateArray))\\\n",
    "                    .withColumn(\"time_diff\", find_diff_udf(groupedDF.dateArray))\\\n",
    "                    .withColumn(\"call_id\", groupedDF.call)\\\n",
    "                    .withColumn(\"recording\", get_if_active_udf(groupedDF.recordingArray))\\\n",
    "                    .withColumn(\"streaming\", get_if_active_udf(groupedDF.streamingArray))\\\n",
    "                    .withColumn(\"locked\", get_if_locked_udf(groupedDF.lockStateArray))\\\n",
    "                    .withColumn(\"cospace\", get_if_cospace_udf(groupedDF.callType))\\\n",
    "                    .withColumn(\"adhoc\", get_if_adhoc_udf(groupedDF.callType))\\\n",
    "                    .withColumn(\"lync_conferencing\", get_if_lync_udf(groupedDF.callType))\\\n",
    "                    .withColumn(\"forwarding\", get_if_forwarding_udf(groupedDF.callType))\\\n",
    "                    .select(\"current_time\", \"time_diff\", \"call_id\", \"recording\", \"streaming\", \n",
    "                            \"locked\", \"cospace\", \"adhoc\", \"lync_conferencing\", \"forwarding\",\n",
    "                            \"current_participants\", \"mean_participants\", \"max_participants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- current_time: string (nullable = true)\n",
      " |-- time_diff: string (nullable = true)\n",
      " |-- call_id: string (nullable = true)\n",
      " |-- recording: string (nullable = true)\n",
      " |-- streaming: string (nullable = true)\n",
      " |-- locked: string (nullable = true)\n",
      " |-- cospace: string (nullable = true)\n",
      " |-- adhoc: string (nullable = true)\n",
      " |-- lync_conferencing: string (nullable = true)\n",
      " |-- forwarding: string (nullable = true)\n",
      " |-- current_participants: long (nullable = true)\n",
      " |-- mean_participants: double (nullable = true)\n",
      " |-- max_participants: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = finalDF.withColumn(\"id\", concat_udf(func.array(finalDF.call_id, finalDF.current_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- current_time: string (nullable = true)\n",
      " |-- time_diff: string (nullable = true)\n",
      " |-- call_id: string (nullable = true)\n",
      " |-- recording: string (nullable = true)\n",
      " |-- streaming: string (nullable = true)\n",
      " |-- locked: string (nullable = true)\n",
      " |-- cospace: string (nullable = true)\n",
      " |-- adhoc: string (nullable = true)\n",
      " |-- lync_conferencing: string (nullable = true)\n",
      " |-- forwarding: string (nullable = true)\n",
      " |-- current_participants: long (nullable = true)\n",
      " |-- mean_participants: double (nullable = true)\n",
      " |-- max_participants: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToCassandra(writeDF, epochId):\n",
    "     writeDF.write \\\n",
    "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "        .options(table=\"test\", keyspace=\"engineering\")\\\n",
    "        .mode(\"append\") \\\n",
    "        .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = testDF\\\n",
    "        .writeStream\\\n",
    "        .trigger(processingTime=\"10 seconds\") \\\n",
    "        .outputMode(\"update\")\\\n",
    "        .foreachBatch(writeToCassandra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = writer.start()\n",
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
